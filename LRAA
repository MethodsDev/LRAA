#!/usr/bin/env python
# encoding: utf-8

import sys, os, re
import pysam
import argparse
import subprocess
from collections import defaultdict

sys.path.insert(0, os.path.sep.join([os.path.dirname(os.path.realpath(__file__)), "pylib"]))
from Splice_graph import Splice_graph
from PASA_SALRAA import PASA_SALRAA
from Transcript import Transcript, GTF_contig_to_transcripts
from Quantify import Quantify
import Util_funcs
import PASA_SALRAA_Globals
import MultiProcessManager as mpm
import logging



#FORMAT = "%(asctime)-15s %(levelname)s %(module)s.%(name)s.%(funcName)s at %(lineno)d :\n\t%(message)s\n"
FORMAT = "%(asctime)-15s %(levelname)s %(module)s.%(name)s.%(funcName)s:\n\t%(message)s\n"

logger = logging.getLogger()
logging.basicConfig(format=FORMAT, level=logging.INFO)


def main():

    parser = argparse.ArgumentParser(description="LRAA: Long Read Alignment Assembler",
                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)

    parser.add_argument("--bam", type=str, required=True, help="target bam file")
    parser.add_argument("--genome", type=str, required=True, help="target genome file")

    parser.add_argument("--gtf", type=str, required=False, help="GTF to incorporate as guide during reconstruction or for targeting quant-only")
    
    parser.add_argument("--output_prefix", type=str, default="LRAA", help="prefix for output filenames")

    parser.add_argument("--single_best_only", action='store_true', default=False,
                        help="only report the single highest scoring isoform per component")

    parser.add_argument("--CPU", type=int, default=1,
                        help="number of cores for multithreading")


    parser.add_argument("--normalize_max_cov_level", type=int, default=10000, help="normalize to max read coverage level before assembly (default: 10000)")

    parser.add_argument("--quant_only", action='store_true', default=False, help="perform quantification only (must specify --gtf with targets for quant)")
    
    ## debug params
    
    debug_group = parser.add_argument_group("debug settings")

    
    debug_group.add_argument("--debug", "-d", action='store_true', default=False,
                        help='debug mode, more verbose')

    debug_group.add_argument("--mpm_monitor", action='store_true', default=False) # multiprocessing monitor


    ## config settings

    config_group = parser.add_argument_group("config settings")

    # disabling spacers for now - important for illumina or dirty long reads
    #config_group.add_argument("--allow_spacers", action='store_true', default=False)

    config_group.add_argument("--min_path_score", type=float, default=PASA_SALRAA_Globals.config['min_path_score'], help="minimum score for an isoform to be reported")

    config_group.add_argument("--min_per_id", type=float, default=PASA_SALRAA_Globals.config['min_per_id'], help='min per_id for pacbio read alignments')
    

    ## alt splice settings

    config_group_altsplice = parser.add_argument_group("alt splice settings")

    # TODO:// mv splice defaults to globals.config
    config_group_altsplice.add_argument("--min_alt_splice_freq", type=float, default=0.02, help="min fraction required for alt splicing at an exon boundary (default: 0.02)")
    config_group_altsplice.add_argument("--min_alt_unspliced_freq", type=float, default=0.05, help="min fraction required for retained intron at splice boundary (default: 0.05)")
    
    
    ## restrict to contig and optionally region of contig

    contig_group_setting = parser.add_argument_group("target specific contig (or region of contig)")

    contig_group_setting.add_argument("--restrict_to_contig", type=str, default=None,
                                      help="restrict run to single contig")
    contig_group_setting.add_argument("--restrict_region_range", type=str, default=None,
                                      help="restrict to region on contig lend:rend")
    
    args = parser.parse_args()
    
    genome_fasta_filename = args.genome
    bam_filename = args.bam
    output_prefix = args.output_prefix
    single_best_only = args.single_best_only
    CPU = args.CPU
    QUANT_ONLY = args.quant_only
    input_gtf = args.gtf
    
    if args.quant_only and input_gtf is None:
        sys.exit("If running --quant_only, must specify --gtf corresponding to targets of quantification")
    
    # update config
    PASA_SALRAA_Globals.config['min_path_score'] = args.min_path_score
    PASA_SALRAA_Globals.config['min_per_id'] = args.min_per_id
        
    if args.mpm_monitor:
        mpm.set_debug()

    
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
        PASA_SALRAA_Globals.DEBUG = True


    allow_spacers = False
    #allow_spacers = args.allow_spacers

    ## perform normalization prior to assembly
    pre_norm_bam_filename = bam_filename

    bam_file_for_quant = pre_norm_bam_filename
    bam_file_for_sg = pre_norm_bam_filename
    
    if (not QUANT_ONLY) and (args.normalize_max_cov_level > 0):

        bamsifter_prog = os.path.sep.join([os.path.dirname(os.path.realpath(__file__)), "plugins/bamsifter/bamsifter"])

        norm_bam_filename = os.path.basename(bam_filename) + f".norm_{args.normalize_max_cov_level}.bam"
        
        cmd = " ".join([bamsifter_prog,
                        f" -c {args.normalize_max_cov_level} ",
                        f" -o {norm_bam_filename} ",
                        bam_filename])
                        
        norm_bam_checkpoint = norm_bam_filename + ".ok"
        if not os.path.exists(norm_bam_checkpoint):
            logger.info("generating normalized bam file")
            logger.info(cmd)
            subprocess.check_call(cmd, shell=True)

            samtools_index_cmd = f"samtools index {norm_bam_filename}" 
            subprocess.check_call(samtools_index_cmd, shell=True)

            subprocess.check_call(f"touch {norm_bam_checkpoint}", shell=True)


        bam_file_for_sg = norm_bam_filename


    ###########################################
    ## on to isoform discovery / reconstruction 
            

    splice_graph_params_dict = { 'read_aln_gap_merge_int' :  10,
                                 'inter_exon_segment_merge_dist' : 50,
                                 'max_genomic_contig_length' : 1e10,
                                 'min_alt_splice_freq' : args.min_alt_splice_freq,
                                 'min_alt_unspliced_freq' : args.min_alt_unspliced_freq,
                                 'max_intron_length_for_exon_segment_filtering' : 10000,
                                 'min_intron_support' : 1,
                                 'min_terminal_splice_exon_anchor_length' : 15,
                                 'remove_unspliced_introns' : False }
    # TODO:// put above settings into the config and add to cmd line interface
    
    Splice_graph.init_sg_params(splice_graph_params_dict)
    
    
    # data structures want:
    # ultimately exons and introns
    # build from reads.
    # define coverage intervals and introns as graph components.



    if args.restrict_to_contig:
        genome_contigs_list = [args.restrict_to_contig]
    else:
        genome_contigs_list = get_genome_contigs_listing(genome_fasta_filename)

    restrict_region_lend, restrict_region_rend = None, None
    if args.restrict_region_range:
        restrict_region_lend, restrict_region_rend = re.split("[\\:\\-]", args.restrict_region_range)
        restrict_region_lend = int(restrict_region_lend)
        restrict_region_rend = int(restrict_region_rend)
        assert restrict_region_lend < restrict_region_rend, f"Error, {args.restrict_region_range} invalid range"


    prereconstruct_info_dir = "__prereconstruct"
    if not os.path.exists(prereconstruct_info_dir):
        os.makedirs(prereconstruct_info_dir)


    contig_to_input_transcripts = defaultdict(list)
    if input_gtf:
        logger.info(f"-capturing input transcripts from gtf {input_gtf}")
        contig_to_input_transcripts = GTF_contig_to_transcripts.parse_GTF_to_Transcripts(input_gtf)
        
    ##----------------------------------------------
    ## Begin, target each contig separately

    ofh_quant_read_tracker = None
    if QUANT_ONLY:
        output_filename = f"{output_prefix}.quant.expr"
        ofh_quant_read_tracking_filename = f"{output_prefix}.quant.tracking"
        ofh_quant_read_tracker = open(ofh_quant_read_tracking_filename, "wt")
    else:
        output_filename = f"{output_prefix}.gtf"
        
    ofh = open(output_filename, 'wt')
    
    for contig_acc in genome_contigs_list:

        logger.info(f"-processing contig: {contig_acc}")

        ##-------------------
        ## build splice graph

        sg = Splice_graph()

        contig_seq_str = Util_funcs.retrieve_contig_seq_from_fasta_file(contig_acc, genome_fasta_filename)

        input_transcripts = contig_to_input_transcripts[contig_acc]

        if input_transcripts is not None and len(input_transcripts) == 0:
            input_transcripts = None
        

        if QUANT_ONLY:

            # get path assignments for the input transcripts
            # get the path assignments for the reads.
            # compare read mappings, assign categories


            # for quant only, build sg only based on the input gtf and not the alignments in the bam
            sg.build_splice_graph_for_contig(contig_acc, contig_seq_str,
                                             bam_file_for_sg,
                                             restrict_region_lend, restrict_region_rend, input_transcripts)

            if sg.is_empty():
                logger.info(f"-no splice graph created for contig: {contig_acc}.... skipping.")
                continue

            if PASA_SALRAA_Globals.DEBUG:
                sg.write_intron_exon_splice_graph_bed_files("{}/__prereconstruct.{}.pad1".format(prereconstruct_info_dir, contig_acc), pad=1)



            pasa_salraa_obj = PASA_SALRAA(sg, CPU)
            pasa_salraa_obj.assign_transcripts_paths_in_graph(input_transcripts)

            mp_counter = pasa_salraa_obj._populate_read_multi_paths(contig_acc, contig_seq_str, bam_file_for_quant)
            q = Quantify(sg)
            q.quantify(input_transcripts, mp_counter)
            q.report_quant_results(input_transcripts, ofh, ofh_quant_read_tracker)

            
        else:
            ##---------------------
            ## Assemble transcripts

            sg.build_splice_graph_for_contig(contig_acc, contig_seq_str, bam_file_for_sg, restrict_region_lend, restrict_region_rend, input_transcripts)

            if sg.is_empty():
                logger.info(f"-no splice graph created for contig: {contig_acc}.... skipping.")
                continue

            if PASA_SALRAA_Globals.DEBUG:
                sg.write_intron_exon_splice_graph_bed_files("{}/__prereconstruct.{}.pad1".format(prereconstruct_info_dir, contig_acc), pad=1)

            
            pasa_salraa_obj = PASA_SALRAA(sg, CPU)
            logger.info(f"-building splice graph for {contig_acc}")
            pasa_salraa_obj.build_multipath_graph(contig_acc, contig_seq_str, bam_file_for_sg, allow_spacers)

            logger.info(f"-begin reconstructing isoforms for {contig_acc}")
            transcripts = pasa_salraa_obj.reconstruct_isoforms(single_best_only)

            ## TODO://gene clustering
            
            logger.info("writing gtf output for {} containing {} transcripts".format(contig_acc, len(transcripts)))
            for transcript in transcripts:
                ofh.write(transcript.to_GTF_format() + "\n")


    ofh.close()
    if QUANT_ONLY:
        ofh_quant_read_tracker.close()

    
    return
    

def get_genome_contigs_listing(genome_fasta_filename):

    fai_file = "{}.fai".format(genome_fasta_filename)
    if not os.path.exists(fai_file):
        subprocess.check_call("samtools faidx {}".format(genome_fasta_filename),
                              shell=True)

    contigs_list = list()
    
    with open(fai_file) as fh:
        for line in fh:
            vals = line.split("\t")
            contig_acc = vals[0]
            contigs_list.append(contig_acc)

    return contigs_list
    
            
if __name__ == '__main__':
    main()
